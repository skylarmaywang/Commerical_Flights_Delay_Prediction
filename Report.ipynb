{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a55ae2f-d74a-44f6-8fad-0d23f0a7e7a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 261 FA2025 TEAM 3_3 PHASE 3 REPORT\n",
    "### Project Title: ML at Scale for Freight Delivery Reliability: A Flight Delay Prediction Approach\n",
    "_Phase Leader: Kevin Pradjinata_\n",
    "\n",
    "---\n",
    "## Team Information\n",
    "\n",
    "| Phase # | Phase Leader | Contact | Photo |\n",
    "|---------|--------------|---------|-------|\n",
    "| 1 | Elaine Chan | elaine.chan@berkeley.edu | <img src=\"https://raw.githubusercontent.com/skylarmaywang/261_Final/main/elaine.png\" width=\"100\" height=\"100\" style=\"object-fit: cover; border-radius: 8px;\"> |\n",
    "| 2 | Skylar Wang | skylarmwang@berkeley.edu | <img src=\"https://raw.githubusercontent.com/skylarmaywang/261_Final/main/skylar.png\" width=\"100\" height=\"100\" style=\"object-fit: cover; border-radius: 8px;\"> |\n",
    "|  | Noah Cederholm | nmceder@berkeley.edu | <img src=\"https://raw.githubusercontent.com/skylarmaywang/261_Final/main/noah.png\" width=\"100\" height=\"100\" style=\"object-fit: cover; border-radius: 8px;\"> |\n",
    "| 3 | Kevin Pradjinata | kpradjinata@berkeley.edu | <img src=\"https://raw.githubusercontent.com/skylarmaywang/261_Final/main/kevin.png\" width=\"100\" height=\"100\" style=\"object-fit: cover; border-radius: 8px;\"> |\n",
    "|  | Vivrd Prasanna | vivrd@berkeley.edu | <img src=\"https://raw.githubusercontent.com/skylarmaywang/261_Final/main/vivrd.png\" width=\"100\" height=\"100\" style=\"object-fit: cover; border-radius: 8px;\"> |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef74445d-86a3-47d6-9478-cd9db537619d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Credit Assignment Plan\n",
    "\n",
    "| Team Member | Phase | Task | Specifics | Start Date | End Date | Time Commited |\n",
    "|------------|-------|------|-----------|------------|----------|----------------|\n",
    "| **Elaine** | **1** | Abstract | Define business metrics | 2025-10-20 | 2025-11-03 | 0.5 |\n",
    "| | | ML Algorithms & Metrics | ML algorithms, metrics, loss functions | | | 1.0 |\n",
    "| | | Machine Learning Pipeline | Block diagram | | | 0.5 |\n",
    "| | | Phase Leader Plan | Coordinate team deliverables | | | 0.5 |\n",
    "| | | Credit Assignment Plan | Define task allocation | | | 0.5 |\n",
    "| | | Report | Phase 1 report writing | | | 2.0 |\n",
    "| | **2** | Presentation | Create slides for business problem and dataset overview | 2025-10-20 | 2025-11-24 | 3.0 |\n",
    "| | | EDA | Delay EDA on 3-month dataset | | | 3.0 |\n",
    "| | **3** | Presentation | Phase 3 presentation slides | 2025-11-24 | 2025-12-14 | 3.0 |\n",
    "| | | Credit Plan Updates | Update credit assignment | | | 0.5 |\n",
    "| | | Abstract | Update abstract for Phase 3 | | | 0.5 |\n",
    "| | | Data & Feature Engineering | Feature engineering documentation | | | 10.0 |\n",
    "| | | Leakage | Leakage prevention and control section | | | 4.0 |\n",
    "| | | Results & Discussion | Results analysis and discussion | | | 4.0 |\n",
    "| | | Conclusion | Conclusion section writing | | | 3.0 |\n",
    "| | | Report Compilation | Final report assembly | | | 5.0 |\n",
    "| **Noah** | **1** | Data Description | Data dictionary, data size, source, checkpoint strategy | 2025-10-20 | 2025-11-03 | 1.0 |\n",
    "| **Vivrd** | **1** | Data Description | Missing/duplicate plan + quick EDA (summary statistics) | 2025-10-20 | 2025-11-03 | 2.0 |\n",
    "| | **2** | EDA | 3-month & 12-month delay data; raw + derived feature plan | 2025-10-20 | 2025-11-24 | 3.0 |\n",
    "| | | Presentation | Slides for EDA, data preparation, feature engineering | | | 0.5 |\n",
    "| **Skylar** | **1** | ML Algorithms & Metrics | ML algorithms, metrics, loss functions, equations | 2025-10-20 | 2025-11-03 | 1.5 |\n",
    "| | **2** | Presentation | Modeling pipeline and conclusion slides | 2025-10-20 | 2025-11-24 | 1.0 |\n",
    "| | | Project Abstract | Update abstract; reframe business problem | | | 2.0 |\n",
    "| | | EDA | 12-month temporal, operational, weather EDA | | | 3.0 |\n",
    "| | | Modeling Pipelines | Input features, loss functions, experiment table, TS-CV | | | 5.0 |\n",
    "| | | Results & Discussion | Review experiments, discuss results | | | 1.0 |\n",
    "| | | Conclusion | Restate hypothesis, summarize points, future work | | | 0.5 |\n",
    "| | **3** | EDA / Feature Engineering | EDA and feature engineering on full dataset | 2025-11-24 | 2025-12-14 | 10.0 |\n",
    "| | | Modeling | Code GBT and MLP models; time-based CV, early stopping | | | 12.0 |\n",
    "| | | Report Writing | Data & feature engineering, leakage, modeling pipelines | | | 5.0 |\n",
    "| **Kevin** | **1** | Machine Learning Pipeline | Create ML pipeline from ingestion to model | 2025-10-20 | 2025-11-03 | 1.5 |\n",
    "| | **2** | Machine Learning Pipelines | Code vector assembly, scaling, encoding; train baseline | 2025-10-20 | 2025-11-24 | 3.0 |\n",
    "| | **3** | Modeling | Code GBT and MLP models; time-based CV | 2025-10-20 | 2025-12-13 | 15.0 |\n",
    "| | | Project Description | Define tasks; create workflow diagram | | | 1.5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95935484-e90e-4e70-ad5e-aff45bde527f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 1. Abstract\n",
    "\n",
    "This project predicts U.S. commercial flight departure delays (in minutes) using the OTPW dataset, enabling dynamic pricing of cargo delivery guarantees. The dataset combines flight records from the U.S. Department of Transportation Bureau of Transportation Statistics with NOAA weather observations and airport metadata, totaling 31.7 million flights × 214 features spanning 2015–2019.\n",
    "\n",
    "We implemented and compared four modeling approaches: Linear Regression (baseline), Gradient Boosted Trees (GBT), and two Multilayer Perceptron (MLP) neural network architectures. Using expanding-window time-series cross-validation across 2015–2018 with 2019 as a blind test set, we evaluated models using both RMSE and MAE metrics.\n",
    "\n",
    "The Gradient Boosted Trees model achieved the best overall performance with Test RMSE of 48.01 minutes and MAE of 20.45 minutes. Key predictive features include origin airport, departure hour, carrier reliability metrics (7-day rolling window), and weather interaction terms. At an industry-standard cost of $100.76 per minute of delay, a 20-minute MAE translates to approximately $2,015 uncertainty per flight prediction, enabling risk-differentiated pricing of cargo delivery guarantees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40b0a0cc-369f-47d3-b5b3-414443555149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Model | CV RMSE | Test RMSE | Test MAE | Δ from Baseline |\n",
    "|-------|---------|-----------|----------|-----------------|\n",
    "| Linear Regression (Baseline) | 44.11 | 48.30 | 20.78 | — |\n",
    "| **GBT (Best Overall)** | **41.86** | **48.01** | **20.45** | **-0.29** |\n",
    "| MLP-1 [128] | 42.05 | 48.13 | 20.89 | -0.17 |\n",
    "| MLP-2 [64, 32] | 42.06 | 48.07 | 19.89 | -0.23 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ac8dcc2-26a0-488c-9658-e18ff2245600",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 2. Introduction: The Business Problem\n",
    "\n",
    "###Flight Delays Cost the U.S. Air Cargo Industry Billions Annually\n",
    "Flight delays in U.S. commercial aviation create costly ripple effects across the national airspace system, affecting airlines, airports, passengers, and critically, air cargo operations. According to AirHelp estimates cited in the OAG/Microsoft 2025 AI in Aviation report [1], total U.S. flight delay costs exceeded $34 billion in 2022 when accounting for both airline operational costs and passenger time lost. With cargo revenues representing approximately 15.6% of total airline revenues in 2025 [5], flight delays significantly impact time-sensitive cargo operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "102bfe8b-045e-4a59-9c70-e39ae883ab4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###The Scale of the Problem\n",
    "\n",
    "| Metric | Value | Source |\n",
    "|--------|-------|--------|\n",
    "| U.S. domestic flights arriving late (15+ min) | ~22% | U.S. DOT Air Travel Consumer Report (2024) [2] |\n",
    "| Average cost of delay to airlines | $100.76 per minute | Airlines for America (2024) [3] |\n",
    "| Major cargo hub daily operations | 1,500+ flights | Industry estimates |\n",
    "| FedEx/UPS Money-Back Guarantee threshold | 60 seconds | FedEx Service Guide [4] |\n",
    "\n",
    "*Note: The 22% delay rate is derived from the 2024 on-time arrival rate of ~78% reported by DOT [2]. Cost per minute reflects block time operational costs from DOT Form 41 data [3].*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab66a655-465c-4dd0-baf1-6f541a48945a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Translating Delay Predictions to Business Value\n",
    "\n",
    "Understanding the monetary implications of prediction error is critical for business decision-making:\n",
    "\n",
    "| Prediction Error | Monetary Impact | Business Interpretation |\n",
    "|-----------------|-----------------|------------------------|\n",
    "| **MAE = 20.45 min** | **$2,061 per flight** | Typical prediction uncertainty |\n",
    "| **RMSE = 48.01 min** | **$4,839 per flight** | Worst-case scenario exposure |\n",
    "| 1 minute improvement in MAE | **$100.76 saved per flight** | Marginal value of accuracy |\n",
    "| 5 minute improvement in MAE | **$503.80 saved per flight** | Meaningful operational savings |\n",
    "\n",
    "At ~6.3 million annual U.S. domestic flights [6], even a **1-minute improvement in MAE represents ~$635 million in better-allocated risk pricing** across the industry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "129f3826-334c-4d3b-89b2-309c8fe672ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Why Both RMSE and MAE Matter for This Business Problem\n",
    "\n",
    "| Metric | Formula | Business Relevance |\n",
    "|--------|---------|-------------------|\n",
    "| **RMSE** | √(Σ(y-ŷ)²/N) | Penalizes large errors heavily; critical for catastrophic delay risk management |\n",
    "| **MAE** | Σ\\|y-ŷ\\|/N | Represents typical operational error; drives day-to-day pricing decisions |\n",
    "\n",
    "**RMSE is higher than MAE** (48.01 vs 20.45) because the delay distribution is heavily right-skewed. Rare extreme delays (up to 999 minutes) inflate squared error terms. For cargo guarantee pricing:\n",
    "\n",
    "- **Use MAE** to set baseline pricing (typical expected error)\n",
    "- **Use RMSE** to price risk premiums for catastrophic delay protection\n",
    "- **The gap (RMSE - MAE ≈ 28 min)** quantifies exposure to extreme delay events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01c5b6d8-3f22-4cf7-b65f-829858fe40e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 3. Data Lineage and Key Data Transformations\n",
    "\n",
    "### 3.1 Data Sources\n",
    "\n",
    "| Component | Source | Rows × Cols | Purpose | Size (GB) |\n",
    "|-----------|--------|-------------|---------|----------|\n",
    "| **Flights** | U.S. DOT TranStats On-Time Performance | ≈ 31.7M × 109 | Flight schedules, carriers, delays | 2.74 |\n",
    "| **Weather** | NOAA Global Hourly / Daily | ≈ 630.9M × 177 | Hourly meteorological variables | 32.64 |\n",
    "| **Airport Metadata** | U.S. DOT Stations / DataHub Codes | ≈ 18K × 10 | Location and code joins | 0.05 |\n",
    "| **Joined OTPW** | Flights × Weather × Airport | ≈ 31.7M × 214 | Final modeling dataset | 5.51 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0529dbf3-8067-4175-9fdf-f4cba35237b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.2 Data Cleaning\n",
    "\n",
    "| Cleaning Step | Rows Affected | Rationale |\n",
    "|--------------|---------------|----------|\n",
    "| Remove cancelled flights | ~475K removed | No departure delay for cancelled flights |\n",
    "| Remove null DEP_DELAY | ~1K removed | Target variable cannot be null |\n",
    "| **Final Dataset** | **31,197,330 rows** | Clean dataset for modeling |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fc3ca9c-74d5-4029-8c0b-d98b0501e262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.3 Target Variable Statistics\n",
    "\n",
    "**`DEP_DELAY`** — Departure delay in minutes (negative = early, positive = late)\n",
    "\n",
    "| Statistic | Value |\n",
    "|-----------|-------|\n",
    "| Count | 31,197,330 |\n",
    "| Mean | 9.85 minutes |\n",
    "| Std Dev | 43.48 minutes |\n",
    "| Min | -1.0 minutes |\n",
    "| Median (50%) | -2.0 minutes |\n",
    "| Max | 999.0 minutes |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04a82ac6-8c23-449f-bb1d-88a4641cd14a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3.4 Temporal Split Strategy\n",
    "\n",
    "| Split | Years | Flights | Purpose |\n",
    "|-------|-------|---------|--------|\n",
    "| Training (CV) | 2015–2017 | ~18.8M | Model fitting with expanding window |\n",
    "| Validation | 2018 | ~6.3M | Hyperparameter tuning |\n",
    "| Test (Blind) | 2019 | ~6.1M | Final evaluation |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0a7ff44-c957-41df-980d-500947dcf5a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 4. Feature Engineering\n",
    "\n",
    "### 4.1 Feature Engineering Summary Table\n",
    "\n",
    "| Family | Feature | Type | Window/Method | Rationale | EDA Finding |\n",
    "|--------|---------|------|---------------|-----------|-------------|\n",
    "| **Temporal** | HOUR_OF_DAY | Categorical (0-23) | Extracted from CRS_DEP_TIME | Delays accumulate throughout day | ~2 min (6 AM) → ~16 min (6 PM) |\n",
    "| | DAY_OF_WEEK | Categorical (1-7) | Extracted from FL_DATE | Weekend vs weekday patterns | Thu/Fri peak; Sat lowest |\n",
    "| | SEASON | Categorical | Derived from MONTH | Seasonal weather patterns | Summer highest; Fall lowest |\n",
    "| | IS_PEAK_HOUR | Binary | 1 if 15:00-20:00 | Peak congestion hours | 15.0 vs 7.2 min (2× difference) |\n",
    "| | IS_EARLY_MORNING | Binary | 1 if < 06:00 | First flights have no propagated delays | ~50% lower delays |\n",
    "| | IS_HOLIDAY | Binary | Federal holiday match | Volume and staffing effects | Similar delays on holidays |\n",
    "| **Weather** | FOG_RISK | Binary | visibility < 2mi AND humidity > 90% | Fog conditions | 17.5 vs 10.0 min (+75%) |\n",
    "| | STORM_RISK | Binary | wind > 20mph AND humidity > 80% | Storm conditions | 20.0 vs 10.0 min (+100%) |\n",
    "| | INT_VISIBILITY_HUMIDITY | Continuous | visibility × humidity | Fog severity interaction | More stable signal than raw |\n",
    "| | INT_WIND_HUMIDITY | Continuous | wind_speed × humidity | Storm severity interaction | Captures conditional effects |\n",
    "| **Time-Series** | carrier_delay_freq_7d | Continuous | **7-day rolling window** | Recent carrier reliability | Top 5 feature importance |\n",
    "| | carrier_route_delay_freq_30d | Continuous | **30-day rolling window** | Route-specific reliability | Top 10 feature importance |\n",
    "| **Graph** | ORIGIN_AIRPORT_PAGERANK | Continuous | PageRank (α=0.15, 20 iter) | Hub airport centrality | High PR airports = more delays |\n",
    "| **Flight** | CRS_ELAPSED_TIME | Continuous | Direct | Scheduled duration buffer | Long-haul operational differences |\n",
    "| | DISTANCE | Continuous | Direct | Route distance | Short vs long haul patterns |\n",
    "| **Categorical** | OP_UNIQUE_CARRIER | Index (~18 values) | StringIndexer | Airline operational quality | JetBlue ~15 min; Hawaiian ~1 min |\n",
    "| | ORIGIN | Index (~350 values) | StringIndexer | Origin airport characteristics | Eastern hubs higher delays |\n",
    "| | DEST | Index (~350 values) | StringIndexer | Destination airport characteristics | Network effects |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aec250f9-4b69-4091-952d-bbd7b93ce1db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.2 Critical Design Decision: Rolling Window vs. Expanding Window\n",
    "\n",
    "Our time-series features use **rolling (sliding) windows** rather than expanding windows:\n",
    "\n",
    "| Approach | Implementation | Use Case in Our Pipeline |\n",
    "|----------|---------------|-------------------------|\n",
    "| **Rolling Window** | Fixed lookback (7 or 30 days) | Time-series features (carrier_delay_freq_7d, carrier_route_delay_freq_30d) |\n",
    "| **Expanding Window** | All historical data | Cross-validation strategy (2015→2016, 2015-16→2017, etc.) |\n",
    "\n",
    "**Why Rolling Windows for Feature Engineering:**\n",
    "\n",
    "1. **Recency Bias**: Recent operational reliability (last 7-30 days) is more predictive than lifetime averages\n",
    "2. **Regime Changes**: Airlines change equipment, staffing, and routes over time; old data may mislead\n",
    "3. **Computational Efficiency**: Fixed window size enables efficient Spark window operations\n",
    "4. **Production Realism**: In deployment, we'd use recent data, not retrain on all history daily\n",
    "\n",
    "**Implementation Details:**\n",
    "```python\n",
    "# 7-day rolling window (exclude current day to prevent leakage)\n",
    "w_carrier_7d = (\n",
    "    Window.partitionBy(\"OP_UNIQUE_CARRIER\")\n",
    "          .orderBy(F.col(\"FL_DATE_TS\").cast(\"long\"))\n",
    "          .rangeBetween(-7 * 86400, -1)  # -1 excludes current day\n",
    ")\n",
    "\n",
    "# Bayesian smoothing to stabilize low-volume estimates\n",
    "alpha = 10\n",
    "prior_delay_rate = 0.15\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"carrier_delay_freq_7d\",\n",
    "    (F.sum(\"is_delayed\").over(w_carrier_7d) + alpha * prior_delay_rate) /\n",
    "    (F.count(\"*\").over(w_carrier_7d) + alpha)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db897dd7-cbc8-47bb-9c2a-8c2146ca5a3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "-----\n",
    "## 5. Leakage Prevention and Control\n",
    "\n",
    "### 5.1 Definition of Data Leakage\n",
    "\n",
    "**Data leakage** occurs when information that would not be available at prediction time is used during model training, leading to overly optimistic performance estimates that fail to generalize. In flight delay prediction, this is particularly critical because many variables are recorded **after** departure.\n",
    "\n",
    "**Hypothetical Example of Leakage:**\n",
    "> Using `ARR_DELAY` (arrival delay) to predict `DEP_DELAY` (departure delay) would be severe leakage. Arrival delay is not known until the flight lands, hours after we need to make our prediction.\n",
    "\n",
    "### 5.2 Feature-Level Leakage Audit\n",
    "\n",
    "All variables unavailable **two hours prior to scheduled departure** were removed:\n",
    "\n",
    "| Category | Variables Removed | Reason |\n",
    "|----------|------------------|--------|\n",
    "| **Actual Times** | DEP_TIME, ARR_TIME, WHEELS_OFF, WHEELS_ON | Recorded after departure |\n",
    "| **Taxi Times** | TAXI_OUT, TAXI_IN | Measured during flight operations |\n",
    "| **Air Time** | AIR_TIME, ACTUAL_ELAPSED_TIME | Computed from actual departure/arrival |\n",
    "| **Arrival Delay** | ARR_DELAY, ARR_DELAY_NEW, ARR_DEL15 | Outcome of flight |\n",
    "| **Delay Breakdown** | CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY | Causal attribution after the fact |\n",
    "| **Status Flags** | CANCELLED, DIVERTED, CANCELLATION_CODE | Determined after departure |\n",
    "| **High-Cardinality IDs** | TAIL_NUM, FL_NUM | May memorize historical patterns |\n",
    "\n",
    "### 5.3 Pipeline-Level Leakage Prevention\n",
    "\n",
    "| Technique | Implementation | Purpose |\n",
    "|-----------|---------------|---------|\n",
    "| **Time-based CV** | Expanding window (2015→2016, 2015-16→2017, 2015-17→2018) | Prevent future information leakage |\n",
    "| **Fit on training only** | StandardScaler, StringIndexer fitted on training data | Prevent validation/test statistics from leaking |\n",
    "| **Rolling windows with lag** | `rangeBetween(-N*86400, -1)` | **Exclude current day** from historical features |\n",
    "| **Blind test set** | 2019 data never used until final evaluation | Unbiased performance estimate |\n",
    "\n",
    "### 5.4 Additional Check\n",
    "\n",
    "| Feature | Status | Evidence |\n",
    "|-----|-----------|----------|\n",
    "| Training on test data | Avoided | 2019 data held out completely until final evaluation |\n",
    "| Using future information | Avoided | Time-based CV; rolling windows exclude current day |\n",
    "| Target leakage | Avoided | 25+ post-departure columns removed |\n",
    "| Feature-target contamination | Avoided | Preprocessors fit only on training folds |\n",
    "| Data duplication across splits | Avoided | Temporal splits with no overlap |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b3f6a2b-8c51-4454-b7d8-1eb9da8613a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Final Modeling Table\n",
    "\n",
    "After cleaning and feature engineering, the modeling table contains:\n",
    "- **Target:** `DEP_DELAY`\n",
    "- **Temporal split variable:** `YEAR` \n",
    "- **18 predictive features prior to encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e5d8cde-f0f5-4ca5-b0a5-3c123ab790ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA was used to understand feature behavior, guide feature engineering, and justify feature inclusion or exclusion.\n",
    "\n",
    "\n",
    "### Target Variable (`DEP_DELAY`) Distribution\n",
    "\n",
    "#### Summary Statistics\n",
    "\n",
    "| Statistic | DEP_DELAY |\n",
    "|---------|-----------|\n",
    "| Count | 31,197,330 |\n",
    "| Mean | 9.85 |\n",
    "| Std Dev | 43.48 |\n",
    "| Min | -1.0 |\n",
    "| Median (50%) | -2.0 |\n",
    "| Max | 999.0 |\n",
    "\n",
    "![delay_distribution](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/delay.png)\n",
    "\n",
    "The target distribution is **heavily right-skewed** with a long tail of extreme delays.  \n",
    "This confirms that:\n",
    "- Typical departure delays are relatively small (median slightly negative, indicating early departures)\n",
    "- Rare extreme delay events dominate overall variance\n",
    "\n",
    "This distribution motivates reporting **both RMSE and MAE** in model evaluation:\n",
    "- **RMSE** captures sensitivity to extreme delays\n",
    "- **MAE** better reflects typical operational error\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db92cebf-35fe-4d09-944f-a3b530923837",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Temporal and Calendar Feature EDA\n",
    "\n",
    "**Features analyzed**\n",
    "- `HOUR_OF_DAY`\n",
    "- `DAY_OF_WEEK`\n",
    "- `SEASON`\n",
    "- `IS_PEAK_HOUR`\n",
    "- `IS_EARLY_MORNING`\n",
    "- `IS_HOLIDAY`\n",
    "\n",
    "![delay_hour](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/delay_hour.png)\n",
    "![delay_dow](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/delay_dow.png)\n",
    "![delay_season](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/delay_season.png)\n",
    "![peak](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/peak.png)\n",
    "![morning](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/morning.png)\n",
    "![holiday](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/holiday.png)\n",
    "\n",
    "\n",
    "\n",
    "**Key observations**\n",
    "- Departure delays increase steadily throughout the day, reflecting congestion and delay propagation.\n",
    "- Early morning flights have the lowest average delays.\n",
    "- Peak-hour flights exhibit significantly higher average delays.\n",
    "- Delay patterns vary by day of week, indicating systematic weekly effects.\n",
    "- Summer shows the highest average delays, while fall has the lowest.\n",
    "- Holiday effects are consistent and non-random.\n",
    "\n",
    "**Conclusion**\n",
    "Temporal and calendar features show clear, structured relationships with `DEP_DELAY`.  \n",
    "Their stability and interpretability justify inclusion of all time-based and calendar indicators in downstream models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23010b3e-1a96-4b46-8ff5-ceeab385120f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Raw Weather Variables EDA\n",
    "\n",
    "**Raw variables explored**\n",
    "- `HourlyVisibility`\n",
    "- `HourlyWindSpeed`\n",
    "- `HourlyRelativeHumidity`\n",
    "- `HourlyDryBulbTemperature`\n",
    "- `HourlyDewPointTemperature`\n",
    "\n",
    "![weather](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/weather.png)\n",
    "![weather1](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/weather1.png)\n",
    "\n",
    "\n",
    "**Key observations**\n",
    "- Lower visibility is associated with higher average delays, particularly under extreme low-visibility conditions.\n",
    "- Higher wind speeds correlate with increased delays, especially at the upper tail.\n",
    "- High relative humidity is associated with increased delays, likely interacting with visibility and precipitation effects.\n",
    "- Temperature and dew point show weak, nonlinear, and context-dependent relationships with delay.\n",
    "- Scatter plots reveal high variance and heavy noise, with effects driven largely by rare extreme conditions.\n",
    "\n",
    "**Conclusion**\n",
    "Raw weather variables exhibit intuitive but **unstable and highly nonlinear** relationships with `DEP_DELAY`.  \n",
    "They are informative for understanding operational risk and guiding feature design, but their raw forms are **not retained** in the final model in favor of engineered indicators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0d7e3b8-9548-4d2c-b2ed-afbb6336f433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Engineered Weather Interaction and Risk Feature EDA\n",
    "\n",
    "**Final weather features**\n",
    "- `FOG_RISK`\n",
    "- `STORM_RISK`\n",
    "- `INT_VISIBILITY_HUMIDITY`\n",
    "- `INT_WIND_HUMIDITY`\n",
    "\n",
    "![fog](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/fog.png)\n",
    "![storm](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/storm.png)\n",
    "![vishumid](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/vishumid.png)\n",
    "![windhumid](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/windhumid.png)\n",
    "\n",
    "**Key observations**\n",
    "- Flights under fog-risk conditions exhibit substantially higher average delays than non-fog flights.\n",
    "- Storm-risk conditions show an even larger increase in average departure delay, indicating strong operational disruption.\n",
    "\n",
    "**Conclusion**\n",
    "Engineered weather risk indicators and interaction terms produce **clear, stable, and interpretable relationships** with `DEP_DELAY`.  \n",
    "They outperform raw weather variables and are retained for downstream modeling as robust representations of weather-related operational risk.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e99001f9-d328-4dcf-8845-fdd86d58346c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Time-Series Operational History EDA\n",
    "\n",
    "**Features**\n",
    "- `carrier_delay_freq_7d`\n",
    "- `carrier_route_delay_freq_30d`\n",
    "\n",
    "**Graphs to include**\n",
    "1. Scatter: `carrier_delay_freq_7d` vs `DEP_DELAY`\n",
    "2. Scatter: `carrier_route_delay_freq_30d` vs `DEP_DELAY`\n",
    "\n",
    "**Analysis**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70dbc023-045f-4927-ba57-563404bb85b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Graph-Based Feature EDA\n",
    "\n",
    "**Feature**\n",
    "- `ORIGIN_AIRPORT_PAGERANK`\n",
    "\n",
    "**Graphs to include**\n",
    "1. Scatter of PageRank and Delay\n",
    "\n",
    "**Analysis**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c5ca9ea-6126-4417-9a23-cb0f468c32f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Final Features\n",
    "\n",
    "#### Temporal / Calendar Features (6)\n",
    "\n",
    "| Feature | Description |\n",
    "|------|------------|\n",
    "| `HOUR_OF_DAY` | Scheduled departure hour |\n",
    "| `DAY_OF_WEEK` | Day of week |\n",
    "| `SEASON` | Season derived from month |\n",
    "| `IS_PEAK_HOUR` | Departure between 15:00–20:00 |\n",
    "| `IS_EARLY_MORNING` | Departure before 06:00 |\n",
    "| `IS_HOLIDAY` | U.S. federal holiday indicator |\n",
    "\n",
    "#### Weather Features (4)\n",
    "\n",
    "| Feature | Description |\n",
    "|------|------------|\n",
    "| `FOG_RISK` | Low visibility with high humidity |\n",
    "| `STORM_RISK` | High wind with high humidity |\n",
    "| `INT_VISIBILITY_HUMIDITY` | Visibility × humidity |\n",
    "| `INT_WIND_HUMIDITY` | Wind speed × humidity |\n",
    "\n",
    "#### Time-Series Operational History Features (2)\n",
    "\n",
    "| Feature | Description |\n",
    "|------|------------|\n",
    "| `carrier_delay_freq_7d` | Carrier delay frequency over last 7 days |\n",
    "| `carrier_route_delay_freq_30d` | Carrier–route delay frequency over last 30 days |\n",
    "\n",
    "#### Graph-Based Feature (1)\n",
    "\n",
    "| Feature | Description |\n",
    "|------|------------|\n",
    "| `ORIGIN_AIRPORT_PAGERANK` | Origin airport PageRank |\n",
    "\n",
    "#### Flight Characteristics (2)\n",
    "\n",
    "| Feature | Description |\n",
    "|------|------------|\n",
    "| `CRS_ELAPSED_TIME` | Scheduled flight duration |\n",
    "| `DISTANCE` | Route distance |\n",
    "\n",
    "#### Categorical Identifiers (3)\n",
    "\n",
    "| Feature | Description |\n",
    "|------|------------|\n",
    "| `OP_UNIQUE_CARRIER` | Airline identifier |\n",
    "| `ORIGIN` | Origin airport |\n",
    "| `DEST` | Destination airport |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9540c976-fb14-4cd4-97aa-65d787a64262",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "----\n",
    "## 6. Modeling Pipelines\n",
    "\n",
    "### 6.1 Pipeline Architecture\n",
    "\n",
    "Two preprocessing pipelines are used:\n",
    "\n",
    "1. **Spark ML pipeline** for Linear Regression and Gradient Boosted Decision Trees (GBDT)\n",
    "2. **Custom PyTorch pipeline** for the Multilayer Perceptron (MLP)\n",
    "\n",
    "Both pipelines follow the same logical structure but differ in implementation.\n",
    "\n",
    "**Spark ML pipeline (LR, GBDT):**\n",
    "1. Categorical feature indexing  \n",
    "2. Numeric feature vector assembly  \n",
    "3. Numeric feature standardization  \n",
    "4. Final feature vector assembly  \n",
    "5. Model training  \n",
    "6. Time-aware validation  \n",
    "7. Blind test evaluation on 2019  \n",
    "\n",
    "**PyTorch pipeline (MLP):**\n",
    "1. Fold-specific preprocessing (numeric normalization, categorical encoding)\n",
    "2. Tensor construction\n",
    "3. Neural network training with early stopping\n",
    "4. Time-series cross-validation\n",
    "5. Blind test evaluation on 2019 \n",
    "\n",
    "This design ensures consistency in feature semantics while allowing model-specific optimization.\n",
    "![pipeline_diagram](https://raw.githubusercontent.com/skylarmaywang/261_Final/main/pipeline_diagram.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fafac8ec-e25c-4473-be9c-9202e3e5a83a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6.2 Feature Encoding Strategy\n",
    "| Type | Count | Features | Encoding |\n",
    "|------|-------|----------|----------|\n",
    "| **Numeric (scaled)** | 9 | `FOG_RISK`, `STORM_RISK`, `INT_VISIBILITY_HUMIDITY`, `INT_WIND_HUMIDITY`, `carrier_delay_freq_7d`, `carrier_route_delay_freq_30d`, `ORIGIN_AIRPORT_PAGERANK`, `CRS_ELAPSED_TIME`, `DISTANCE` | StandardScaler (mean=0, std=1) |\n",
    "| **Categorical (indexed)** | 6 | `OP_UNIQUE_CARRIER`, `ORIGIN`, `DEST`, `HOUR_OF_DAY`, `SEASON`, `DAY_OF_WEEK` | StringIndexer (handleInvalid=\"keep\") |\n",
    "| **Binary (direct)** | 3 | `IS_HOLIDAY`, `IS_EARLY_MORNING`, `IS_PEAK_HOUR` | Direct input (0/1) |\n",
    "| **Total** | **18** | | |\n",
    "\n",
    "### 6.3 Computational Configuration\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| **Cluster** | Databricks Runtime 14.3 LTS |\n",
    "| **Driver** | Standard_DS3_v2 (4 cores, 14 GB) |\n",
    "| **Workers** | 2-8 × Standard_DS3_v2 (autoscaling) |\n",
    "| **GPU** | NVIDIA A10 (for MLP training) |\n",
    "| **Total Data Processed** | ~31.2M rows × 18 features |\n",
    "\n",
    "**Experiment Timing Summary:**\n",
    "\n",
    "| Model | Training Configuration | Wall Time | Notes |\n",
    "|-------|----------------------|-----------|-------|\n",
    "| Linear Regression | Spark ML, full CV | 10 | No hyperparameter tuning |\n",
    "| GBT | 3-fold CV × 3 maxIter values | 30 | Grid search + final fit |\n",
    "| MLP-1 [128] | 3-fold CV, early stopping | 45 | GPU accelerated |\n",
    "| MLP-2 [64, 32] | 3-fold CV, early stopping | 50 | GPU accelerated |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "740599bc-3122-4f51-b42e-68eeb92c666b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Encoding Strategy\n",
    "\n",
    "Feature encoding converts heterogeneous raw inputs into numeric representations suitable for machine learning models.\n",
    "\n",
    "\n",
    "#### Numeric Features (Scaled)\n",
    "\n",
    "The following continuous numeric features are grouped and scaled:\n",
    "\n",
    "| Feature | Description |\n",
    "|------|------------|\n",
    "| `FOG_RISK` | Weather risk indicator derived from visibility and humidity |\n",
    "| `STORM_RISK` | Weather risk indicator derived from wind speed and humidity |\n",
    "| `INT_VISIBILITY_HUMIDITY` | Visibility–humidity interaction |\n",
    "| `INT_WIND_HUMIDITY` | Wind–humidity interaction |\n",
    "| `carrier_delay_freq_7d` | Carrier delay frequency (7-day window) |\n",
    "| `carrier_route_delay_freq_30d` | Carrier–route delay frequency (30-day window) |\n",
    "| `ORIGIN_AIRPORT_PAGERANK` | Graph-based PageRank score |\n",
    "| `CRS_ELAPSED_TIME` | Scheduled flight duration |\n",
    "| `DISTANCE` | Route distance |\n",
    "\n",
    "For Spark models, numeric features are assembled into `numeric_vec` and standardized using `StandardScaler` fit only on training data.  \n",
    "For the MLP, numeric features are normalized using fold-specific mean and standard deviation computed from training data only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35bb6f35-9632-4ab7-8913-3f7758054eaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Categorical Features (Encoded)\n",
    "\n",
    "The following features are treated as categorical:\n",
    "\n",
    "| Feature | Description |\n",
    "|------|------------|\n",
    "| `OP_UNIQUE_CARRIER` | Airline identifier |\n",
    "| `ORIGIN` | Origin airport |\n",
    "| `DEST` | Destination airport |\n",
    "| `HOUR_OF_DAY` | Scheduled departure hour (categorical) |\n",
    "| `SEASON` | Season derived from month |\n",
    "| `DAY_OF_WEEK` | Day-of-week category |\n",
    "\n",
    "For Spark models, categorical features are indexed using `StringIndexer` with `handleInvalid = \"keep\"`.  \n",
    "For the MLP, categorical features are mapped to integer vocabularies learned from training data only.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cb38278-ecc2-48e3-a46b-04b0370578a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Binary Features (Direct Input)\n",
    "\n",
    "The following binary indicators are passed directly into the model inputs:\n",
    "\n",
    "| Feature | Description |\n",
    "|------|------------|\n",
    "| `IS_HOLIDAY` | U.S. federal holiday indicator |\n",
    "| `IS_EARLY_MORNING` | Early morning departure indicator |\n",
    "| `IS_PEAK_HOUR` | Peak congestion hour indicator |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9ca1e7c-5812-4e24-934d-c70c44a25935",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### Vector Assembly and Scaling (Spark Pipeline)\n",
    "\n",
    "The Spark preprocessing pipeline consists of:\n",
    "\n",
    "1. **Numeric vector assembly**  \n",
    "   Numeric features → `numeric_vec` (`handleInvalid = \"skip\"`)\n",
    "\n",
    "2. **Numeric scaling**  \n",
    "   `StandardScaler` with mean centering and variance scaling  \n",
    "   (fit on training data only)\n",
    "\n",
    "3. **Final vector assembly**  \n",
    "   `features` = numeric_scaled + binary features + categorical indices  \n",
    "   (`handleInvalid = \"keep\"`)\n",
    "\n",
    "This ensures numeric features are standardized while categorical and binary features retain semantic meaning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ec3141c-bc12-46d6-ae82-b073c19f29ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Target and Split Columns\n",
    "\n",
    "- **Target variable:** `DEP_DELAY`\n",
    "- **Temporal split variable:** `YEAR`\n",
    "\n",
    "The `YEAR` column is used exclusively for time-based splitting and is never included in the feature vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "215e14a9-6d22-4f09-8d4c-74d477a598cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 7. Loss Functions and Evaluation Metrics\n",
    "\n",
    "### 7.1 Training Loss Function\n",
    "\n",
    "All models optimize **Mean Squared Error (MSE)** as the training objective:\n",
    "\n",
    "$$L(y_i, \\hat{y}_i) = (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "**Regularization Strategy**: No explicit L1/L2 penalty. Regularization achieved through:\n",
    "- Constrained model capacity (tree depth, hidden layer size)\n",
    "- Learning rate control (GBT stepSize=0.05, MLP lr=0.001)\n",
    "- Early stopping based on validation performance\n",
    "\n",
    "### 7.2 Evaluation Metrics with Business Interpretation\n",
    "\n",
    "| Metric | Formula | Business Interpretation | Our Best Result | Dollar Impact |\n",
    "|--------|---------|------------------------|-----------------|---------------|\n",
    "| **RMSE** | √(Σ(y-ŷ)²/N) | Penalizes large errors heavily; risk exposure to extreme delays | 48.01 min | $4,839/flight |\n",
    "| **MAE** | Σ\\|y-ŷ\\|/N | Typical expected error; day-to-day pricing decisions | 20.45 min | $2,061/flight |\n",
    "\n",
    "**Why Report Both:**\n",
    "- **MAE = 20.45 min**: On average, predictions are off by ~20 minutes → use for baseline pricing\n",
    "- **RMSE = 48.01 min**: The model struggles with extreme delays → use for risk premium pricing\n",
    "- **Gap (RMSE - MAE) = 27.56 min**: Quantifies tail risk exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddeecdcb-1099-497e-a073-dd3b97c483bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Loss Functions and Evaluation Metrics\n",
    "\n",
    "All models in Phase 3 are trained and evaluated using consistent regression objectives and error metrics to enable fair comparison across pipelines and modeling frameworks.\n",
    "\n",
    "#### Loss Functions\n",
    "\n",
    "All models optimize **Squared Error** as the data loss.\n",
    "\n",
    "**Data Loss (Squared Error)**\n",
    "\n",
    "$$\n",
    "L(y_i, \\hat{y}_i) = (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "- yᵢ is the true departure delay (in minutes).\n",
    "- ŷᵢ is the predicted departure delay.\n",
    "\n",
    "\n",
    "The total objective minimized during training corresponds to the average of this loss across all observations, equivalent to **Mean Squared Error (MSE)**.\n",
    "\n",
    "No explicit regularization term (e.g., L1 or L2 penalty) is added to the objective. Regularization is achieved implicitly through:\n",
    "- constrained model capacity (tree depth, hidden layer size),\n",
    "- learning rate control,\n",
    "- early stopping based on validation performance.\n",
    "\n",
    "#### Evaluation Metrics\n",
    "\n",
    "Model performance is evaluated using **Root Mean Squared Error (RMSE)** and **Mean Absolute Error (MAE)**.\n",
    "\n",
    "**Root Mean Squared Error (RMSE)**\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}\n",
    "$$\n",
    "\n",
    "**Mean Absolute Error (MAE)**\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{N} \\sum_{i=1}^{N} \\left| y_i - \\hat{y}_i \\right|\n",
    "$$\n",
    "\n",
    "RMSE is used as the **primary metric** for model selection and early stopping, while MAE provides an interpretable measure of average prediction error in minutes.\n",
    "\n",
    "\n",
    "#### Evaluation by Model Type\n",
    "\n",
    "**Linear Regression and GBDT (Spark ML)**  \n",
    "- RMSE and MAE are computed using Spark ML regression evaluators.\n",
    "- Linear Regression uses a time-aware holdout split (2018 validation).\n",
    "- GBDT uses expanding-window time-series cross-validation (2015–2018).\n",
    "- Final evaluation is performed on the 2019 blind test set.\n",
    "\n",
    "**Multilayer Perceptron (MLP)**  \n",
    "- Validation RMSE is computed at the end of each training epoch.\n",
    "- Early stopping is triggered based on validation RMSE.\n",
    "- Final RMSE and MAE are computed on the 2019 blind test set.\n",
    "\n",
    "Using the same loss and evaluation metrics across all models ensures consistency and comparability of results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca95bea5-d884-40c3-b471-9d7c0f90f547",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Models and Hyperparameters\n",
    "\n",
    "This section documents the models explored and the hyperparameters used.\n",
    "\n",
    "### Baseline Model: Linear Regression\n",
    "\n",
    "**Purpose**  \n",
    "Linear Regression provides a transparent baseline for comparison.\n",
    "\n",
    "**Training and Validation Strategy**\n",
    "- Training data: 2015–2017\n",
    "- Validation data: 2018\n",
    "- Evaluation metrics: RMSE and MAE\n",
    "\n",
    "**Hyperparameters**\n",
    "- Loss function: Mean Squared Error\n",
    "- Regularization: None (ordinary least squares)\n",
    "\n",
    "All other parameters are left at Spark ML defaults.  \n",
    "Early stopping is not applicable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7605d02-2912-46e0-84a8-8e5ef8882359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Gradient Boosted Decision Trees (GBDT)\n",
    "\n",
    "**Purpose**  \n",
    "GBDT captures nonlinear relationships and feature interactions in structured tabular data.\n",
    "\n",
    "**Validation Strategy**\n",
    "- Expanding-window time-series cross-validation:\n",
    "  - 2015 → 2016\n",
    "  - 2015–2016 → 2017\n",
    "  - 2015–2017 → 2018\n",
    "\n",
    "**Hyperparameter Grid**\n",
    "\n",
    "| Hyperparameter | Values Explored |\n",
    "|---------------|----------------|\n",
    "| `maxIter` | 40, 80, 120, 160 |\n",
    "| `maxDepth` | 5 |\n",
    "| `minInstancesPerNode` | 5 |\n",
    "| `stepSize` | 0.05 |\n",
    "| `maxBins` | 512 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e388a35-061a-412b-bc7e-4e30d1470d29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Multilayer Perceptron (MLP) Neural Network\n",
    "\n",
    "**Purpose**  \n",
    "The MLP evaluates whether nonlinear representation learning improves performance beyond tree-based models.\n",
    "\n",
    "**Preprocessing**\n",
    "- Custom PyTorch preprocessing\n",
    "- Fold-specific normalization and encoding\n",
    "\n",
    "**Architectures Explored**\n",
    "\n",
    "| Model | Hidden Layers |\n",
    "|------|---------------|\n",
    "| MLP-1 | [64], [128] |\n",
    "| MLP-2 | [64, 32], [128, 64] |\n",
    "\n",
    "**Training Hyperparameters**\n",
    "- Optimizer: Adam\n",
    "- Learning rate: 0.001\n",
    "- Batch size: 131,072\n",
    "- Maximum epochs: 150\n",
    "- Loss function: Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "257e0bac-3b48-4d80-b250-72cdcc219d2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Early Stopping Across Models\n",
    "\n",
    "Early stopping is applied using validation data only and never uses the 2019 test set.\n",
    "\n",
    "**GBDT**\n",
    "- Validation RMSE monitored across boosting iterations\n",
    "- Patience = 1\n",
    "- Training stops when validation RMSE fails to improve\n",
    "\n",
    "**MLP**\n",
    "- Validation RMSE monitored per epoch\n",
    "- Patience = 3 epochs\n",
    "- Training stops when validation RMSE plateaus\n",
    "\n",
    "Early stopping reduces overfitting and unnecessary computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d16ccef-aab3-4f5e-a6dc-7472611b16f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## 8. Model Experiments and Results\n",
    "\n",
    "### 8.1 Baseline: Linear Regression\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| Framework | Spark ML LinearRegression |\n",
    "| Loss | Mean Squared Error (OLS) |\n",
    "| Regularization | None |\n",
    "| Training data | 2015–2017 |\n",
    "| Validation data | 2018 |\n",
    "\n",
    "**Results:**\n",
    "- Validation RMSE: **44.11**\n",
    "- Validation MAE: **19.78**\n",
    "- Test RMSE: **48.30**\n",
    "- Test MAE: **20.78**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27391f40-5eb6-4bfd-8d25-d57e7f135e03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 8.2 Gradient Boosted Decision Trees (GBT)\n",
    "\n",
    "**Hyperparameter Grid Search:**\n",
    "\n",
    "| Parameter | Values Explored | Best Value |\n",
    "|-----------|-----------------|------------|\n",
    "| `maxIter` | 40, 80, 120, 160 | **80** |\n",
    "| `maxDepth` | 5 | 5 |\n",
    "| `minInstancesPerNode` | 5 | 5 |\n",
    "| `stepSize` | 0.05 | 0.05 |\n",
    "| `maxBins` | 512 | 512 |\n",
    "\n",
    "**Cross-Validation Results (Expanding Window):**\n",
    "\n",
    "| Fold | Train Years | Val Year | RMSE | MAE |\n",
    "|------|-------------|----------|------|-----|\n",
    "| 1 | 2015 | 2016 | 38.86 | 17.49 |\n",
    "| 2 | 2015-2016 | 2017 | 42.87 | 18.77 |\n",
    "| 3 | 2015-2017 | 2018 | 43.90 | 19.78 |\n",
    "| **Average** | — | — | **41.86** | **18.68** |\n",
    "\n",
    "**Final Test Results (2019):**\n",
    "- Test RMSE: **48.01**\n",
    "- Test MAE: **20.45**\n",
    "- Wall Time: **~30 minutes**\n",
    "\n",
    "**Detailed Hyperparameter Grid Search Results:**\n",
    "\n",
    "| maxIter | Fold 1 (2015→2016) | Fold 2 (2015-16→2017) | Fold 3 (2015-17→2018) | Avg RMSE | Avg MAE |\n",
    "|---------|-------------------|----------------------|----------------------|----------|---------|\n",
    "| 40 | RMSE=38.88, MAE=17.47 | RMSE=42.87, MAE=18.78 | RMSE=43.89, MAE=19.68 | 41.8827 | 18.6447 |\n",
    "| **80** | **RMSE=38.86, MAE=17.49** | **RMSE=42.83, MAE=18.77** | **RMSE=43.90, MAE=19.78** | **41.8632** | **18.6807** |\n",
    "| 120 | RMSE=38.87, MAE=17.50 | RMSE=42.82, MAE=18.78 | RMSE=44.00, MAE=19.89 | 41.8984 | 18.7233 |\n",
    "\n",
    "*Source: Notebook output lines 9823-10367*\n",
    "\n",
    "**Key Observations from Grid Search:**\n",
    "- Performance improvement plateaus after maxIter=80 (diminishing returns)\n",
    "- Avg RMSE difference between 40 and 80 iterations: 0.0195 points (0.05% improvement)\n",
    "- Increasing to 120 iterations *degrades* performance due to overfitting\n",
    "- Early stopping at maxIter=80 balances accuracy with generalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb7bb3e9-b2bc-487c-931a-28bde19111de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "### 8.3 Multilayer Perceptron (MLP) Neural Networks\n",
    "\n",
    "**Architecture Comparison:**\n",
    "\n",
    "| Model | Hidden Layers | Parameters | Framework |\n",
    "|-------|---------------|------------|-----------|\n",
    "| MLP-1 (shallow) | [128] | ~10K–20K | PyTorch |\n",
    "| MLP-2 (deep) | [64, 32] | ~15K–30K | PyTorch |\n",
    "\n",
    "**Training Configuration:**\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| Optimizer | Adam |\n",
    "| Learning rate | 0.001 |\n",
    "| Batch size | 131,072 |\n",
    "| Max epochs | 150 |\n",
    "| Early stopping patience | 3 epochs |\n",
    "| Loss | MSE |\n",
    "\n",
    "**MLP-1 Cross-Validation Results:**\n",
    "\n",
    "| Fold | Train Years | Val Year | Val RMSE | Epochs to Convergence |\n",
    "|------|-------------|----------|----------|----------------------|\n",
    "| 0 | 2015 | 2016 | 39.04 | 58 |\n",
    "| 1 | 2015-2016 | 2017 | 43.07 | 30 |\n",
    "| 2 | 2015-2017 | 2018 | 44.05 | 42 |\n",
    "| **Average** | — | — | **42.05** | 43 |\n",
    "\n",
    "**MLP-1 Final Test Results:**\n",
    "- Validation RMSE: 40.78\n",
    "- Test RMSE: **48.13**\n",
    "- Test MAE: **20.89**\n",
    "- Wall Time: **~45 minutes**\n",
    "\n",
    "**MLP-2 Cross-Validation Results:**\n",
    "\n",
    "| Fold | Train Years | Val Year | Val RMSE | Epochs to Convergence |\n",
    "|------|-------------|----------|----------|----------------------|\n",
    "| 0 | 2015 | 2016 | 39.04 | 35 |\n",
    "| 1 | 2015-2016 | 2017 | 43.09 | 13 |\n",
    "| 2 | 2015-2017 | 2018 | 44.04 | 31 |\n",
    "| **Average** | — | — | **42.06** | 26 |\n",
    "\n",
    "**MLP-2 Final Test Results:**\n",
    "- Validation RMSE: 40.87\n",
    "- Test RMSE: **48.07**\n",
    "- Test MAE: **19.89**\n",
    "- Wall Time: **~50 minutes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3d2754d-9277-4268-b9a9-d4d8edf716f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 8.4 MLP Training Curves Analysis\n",
    "\n",
    "**MLP-1 [64] Training Progression - Fold 0 (2015→2016):**\n",
    "\n",
    "| Epoch | Val RMSE | Δ from Previous | Status |\n",
    "|-------|----------|-----------------|--------|\n",
    "| 1 | 40.07 | — | Initial |\n",
    "| 5 | 39.42 | -0.65 | Rapid improvement |\n",
    "| 10 | 39.18 | -0.24 | Slowing |\n",
    "| 20 | 39.10 | -0.08 | Fine-tuning |\n",
    "| 30 | 39.07 | -0.03 | Plateau |\n",
    "| 40 | 39.06 | -0.01 | Near convergence |\n",
    "| 48 | 39.05 | -0.01 | Best epoch |\n",
    "| 55 | 39.04 | -0.01 | Final best |\n",
    "| 58 | 39.05 | +0.01 | **Early stopping triggered** (patience=3) |\n",
    "\n",
    "*Source: Notebook output lines 11009-11921*\n",
    "\n",
    "**MLP-1 [64] Training Progression - Fold 1 (2015-2016→2017):**\n",
    "\n",
    "| Epoch | Val RMSE | Δ from Previous | Status |\n",
    "|-------|----------|-----------------|--------|\n",
    "| 1 | 43.98 | — | Initial |\n",
    "| 5 | 43.25 | -0.73 | Rapid improvement |\n",
    "| 10 | 43.16 | -0.09 | Slowing |\n",
    "| 15 | 43.10 | -0.06 | Fine-tuning |\n",
    "| 20 | 43.08 | -0.02 | Near plateau |\n",
    "| 25 | 43.07 | -0.01 | Best region |\n",
    "| 30 | **43.07** | — | **Early stopping** (patience=3) |\n",
    "\n",
    "*Source: Notebook output lines 11937-12305*\n",
    "\n",
    "**Training Dynamics Key Observations:**\n",
    "1. **Rapid initial descent**: 80% of improvement occurs in first 10 epochs\n",
    "2. **Diminishing returns**: After epoch 20, improvements < 0.05 RMSE per epoch\n",
    "3. **Effective early stopping**: Patience=3 prevents overfitting without premature termination\n",
    "4. **Fold-dependent convergence**: Later folds (more training data) converge faster\n",
    "5. **GPU acceleration**: NVIDIA A10 + mixed precision enabled batch size of 131,072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bffdbd16-4ae7-4644-b0e7-bd566f388ba9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 8.5 Early Stopping Effectiveness\n",
    "\n",
    "Early stopping was critical for preventing overfitting in both GBT and MLP models:\n",
    "\n",
    "| Model | Max Possible | Actual Stopped | Epochs Saved | Impact |\n",
    "|-------|--------------|----------------|--------------|--------|\n",
    "| GBT | 160 iterations | 80 iterations | 80 (50%) | Optimal CV RMSE at 80 |\n",
    "| MLP-1 | 150 epochs | 43 avg | 107 (71%) | Prevented overfitting |\n",
    "| MLP-2 | 150 epochs | 26 avg | 124 (83%) | Faster convergence |\n",
    "\n",
    "**Early Stopping Strategy:**\n",
    "- **Data Used**: Validation set (next year in sequence)\n",
    "- **Metric**: Validation RMSE (ML metric aligned with business goal)\n",
    "- **Patience**: 3 epochs/iterations without improvement\n",
    "- **Benefit**: Prevents overfitting while finding optimal complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2520777-59a9-4184-ae58-256c36c33fd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## 9. Results Summary and Model Comparison\n",
    "\n",
    "### 9.1 Comprehensive Results Table\n",
    "\n",
    "| Model | CV RMSE | Test RMSE | Test MAE | Δ RMSE from Baseline | Wall Time |\n",
    "|-------|---------|-----------|----------|---------------------|-----------|\n",
    "| Linear Regression (Baseline) | 44.11 | 48.30 | 20.78 | — | ~10 min |\n",
    "| **GBT (Best Overall)** | **41.86** | **48.01** | 20.45 | **-0.29** | ~30 min |\n",
    "| MLP-1 [128] | 42.05 | 48.13 | 20.89 | -0.17 | ~45 min |\n",
    "| MLP-2 [64, 32] | 42.06 | 48.07 | **19.89** | -0.23 | ~50 min |\n",
    "\n",
    "### 9.2 Feature Importance (GBT)\n",
    "\n",
    "| Rank | Feature | Importance | Category |\n",
    "|------|---------|------------|----------|\n",
    "| 1 | ORIGIN | 23.55% | Categorical |\n",
    "| 2 | HOUR_OF_DAY | 20.06% | Temporal |\n",
    "| 3 | DEST | 9.50% | Categorical |\n",
    "| 4 | INT_VISIBILITY_HUMIDITY | 9.22% | Weather |\n",
    "| 5 | carrier_route_delay_freq_30d | 7.17% | Time-Series |\n",
    "| 6 | SEASON | 6.26% | Temporal |\n",
    "| 7 | INT_WIND_HUMIDITY | 6.08% | Weather |\n",
    "| 8 | carrier_delay_freq_7d | 5.99% | Time-Series |\n",
    "| 9 | DAY_OF_WEEK | 4.40% | Temporal |\n",
    "| 10 | OP_UNIQUE_CARRIER | 3.36% | Categorical |\n",
    "\n",
    "*Source: Notebook output line 10481 - GBT featureImportances.toArray()*\n",
    "\n",
    "**Key Insight**: Airport identity and departure time dominate (>50% combined importance), followed by engineered features (weather interactions, carrier reliability). This validates our feature engineering approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91e113f0-8bf9-482b-b893-476eda9bab41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 9.3 Validation-Test Gap Analysis\n",
    "\n",
    "All models show **~6-7 point RMSE degradation** from CV to test:\n",
    "\n",
    "| Model | CV RMSE | Test RMSE | Gap |\n",
    "|-------|---------|-----------|-----|\n",
    "| GBT | 41.86 | 48.01 | +6.15 |\n",
    "| MLP-1 | 42.05 | 48.13 | +6.08 |\n",
    "| MLP-2 | 42.06 | 48.07 | +6.01 |\n",
    "\n",
    "**Interpretation**: This consistent gap indicates **temporal distribution shift** between 2018 and 2019. Possible causes:\n",
    "- Different weather patterns in 2019\n",
    "- Airline operational changes (new routes, schedule changes)\n",
    "- Air traffic control policy changes\n",
    "- Economic factors affecting travel demand\n",
    "\n",
    "**Implication**: Models require **periodic retraining** (quarterly recommended) to maintain performance in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acb2cbec-0dc4-4e4c-a746-4426b7b9f5ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 10. Discussion\n",
    "\n",
    "### 10.1 Key Findings\n",
    "\n",
    "**1. Tree-based models outperform neural networks on this tabular dataset**\n",
    "- GBT achieves best CV RMSE (41.86) and Test RMSE (48.01)\n",
    "- Neural networks show no clear advantage for this problem\n",
    "- GBT provides interpretable feature importances; MLP does not\n",
    "\n",
    "**2. Engineered features provide significant value**\n",
    "- Time-series features (carrier_delay_freq_7d) rank in top 5\n",
    "- Weather interactions outperform raw weather variables\n",
    "- Graph-based PageRank captures hub effects\n",
    "\n",
    "**3. Temporal distribution shift is the primary challenge**\n",
    "- 6-7 point RMSE gap between CV and test across all models\n",
    "- Models degrade over time; retraining is essential\n",
    "- No model architecture is immune to this shift\n",
    "\n",
    "**4. MAE vs RMSE reveals different strengths**\n",
    "- GBT wins on RMSE (penalizes extreme errors)\n",
    "- MLP-2 wins on MAE (better median predictions)\n",
    "- Business should consider which metric aligns with priorities\n",
    "\n",
    "### 10.2 Limitations\n",
    "\n",
    "| Limitation | Impact | Mitigation |\n",
    "|------------|--------|------------|\n",
    "| Temporal shift | Model degrades over time | Quarterly retraining |\n",
    "| Extreme delays | High RMSE driven by rare events | Consider quantile regression |\n",
    "| Feature availability | Require live weather feeds | Pre-compute features in production |\n",
    "| Single prediction | Point estimate only | Implement prediction intervals |\n",
    "\n",
    "### 10.3 Comparison Across Phases\n",
    "\n",
    "| Phase | Focus | Best Model | Test RMSE | Key Improvement |\n",
    "|-------|-------|------------|-----------|-----------------|\n",
    "| 1 | Problem definition | — | — | Established business metrics |\n",
    "| 2 | Baseline + EDA | Linear Regression | 48.30 | Feature engineering foundation |\n",
    "| 3 | Advanced models | GBT | 48.01 | MLP implementation, time-series features |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afa2ae05-1c6e-4df4-87d3-47fc0eb0bcbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 11. Conclusion\n",
    "### 11.1 Business Implications and ROI Analysis\n",
    "\n",
    "**Model Performance in Business Context:**\n",
    "\n",
    "| Metric | Value | Dollar Impact | Interpretation |\n",
    "|--------|-------|---------------|----------------|\n",
    "| Test MAE | 20.45 min | $2,061/flight | Typical prediction uncertainty |\n",
    "| Test RMSE | 48.01 min | $4,839/flight | Worst-case exposure |\n",
    "| Baseline improvement | 0.29 min RMSE | $29/flight | Marginal improvement |\n",
    "\n",
    "#### ROI Calculation Framework\n",
    "\n",
    "**Industry Cost Assumptions (with Citations):**\n",
    "\n",
    "| Metric | Value | Source |\n",
    "|--------|-------|--------|\n",
    "| Cost per minute of delay | **$100.76** | Airlines for America, \"U.S. Passenger Carrier Delay Costs\" (2024) [3] |\n",
    "| Annual U.S. domestic flights | **~6.3 million** | U.S. DOT Bureau of Transportation Statistics (2019) [6] |\n",
    "| Air cargo share of aviation revenue | **~15.6%** | IATA Industry Outlook (2024) [5] |\n",
    "| Total U.S. flight delay costs | **$34 billion** (2022) | OAG/Microsoft AI in Aviation Report (2025) [1] |\n",
    "\n",
    "**Per-Flight Economic Impact:**\n",
    "\n",
    "| Error Metric | Minutes | Dollar Impact Formula | Per-Flight Cost |\n",
    "|--------------|---------|----------------------|-----------------|\n",
    "| MAE (typical error) | 20.45 | 20.45 × $100.76 | **$2,061** |\n",
    "| RMSE (tail risk exposure) | 48.01 | 48.01 × $100.76 | **$4,839** |\n",
    "| Risk buffer (RMSE - MAE) | 27.56 | 27.56 × $100.76 | **$2,778** |\n",
    "\n",
    "*The risk buffer represents the additional reserve airlines/logistics providers should hold for extreme delay events.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd169669-768c-498a-abbe-c5189642fdbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Industry-Scale Value Estimation:**\n",
    "\n",
    "| Scenario | Calculation | Annual Value |\n",
    "|----------|-------------|--------------|\n",
    "| 1-minute MAE improvement | 6.3M flights × $100.76 | **$635 million** |\n",
    "| GBT vs Baseline (0.33 min MAE improvement) | 6.3M × 0.33 × $100.76 | **$210 million** |\n",
    "| MLP-2 vs Baseline (0.89 min MAE improvement) | 6.3M × 0.89 × $100.76 | **$565 million** |\n",
    "\n",
    "*Note: These estimates assume the full flight network benefits from improved predictions. Actual value depends on deployment scope.*\n",
    "\n",
    "**Cargo-Specific ROI (Estimated):**\n",
    "\n",
    "| Metric | Calculation | Value |\n",
    "|--------|-------------|-------|\n",
    "| Air cargo delay impact | $34B total × 15.6% cargo share [5] | **~$5.3 billion/year** |\n",
    "| Cargo flights affected by 15+ min delays | ~22% of operations [2] | ~1.4M cargo-sensitive flights |\n",
    "| Value of 1-min cargo prediction improvement | 1.4M × $100.76 | **~$141 million/year** |\n",
    "\n",
    "*Sources: [1] OAG (2025), [2] U.S. DOT ATCR (2024), [3] Airlines for America (2024), [5] IATA (2024)*\n",
    "\n",
    "**Validation-Test Gap Business Impact:**\n",
    "\n",
    "The consistent ~6.15 point RMSE gap between CV (41.86) and test (48.01) represents **temporal distribution shift** with direct business implications:\n",
    "\n",
    "| Impact Area | CV Estimate | Test Reality | Gap | Business Cost |\n",
    "|-------------|-------------|--------------|-----|---------------|\n",
    "| Expected error (RMSE) | 41.86 min | 48.01 min | +6.15 min | +$620/flight underestimation |\n",
    "| Annual underestimation | — | — | — | **$3.9 billion** industry-wide if not retrained |\n",
    "\n",
    "*This underscores the critical need for quarterly model retraining to maintain accuracy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec18a505-5a3a-48df-a39d-a8098c91ff3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 11.3 Future Work\n",
    "\n",
    "| Direction | Expected Improvement | Effort |\n",
    "|-----------|---------------------|--------|\n",
    "| Real-time weather integration | More accurate weather features | Medium |\n",
    "| LSTM/Transformer for sequences | Capture temporal dependencies | High |\n",
    "| Airport congestion modeling | Better hub delay prediction | Medium |\n",
    "| Ensemble (GBT + MLP) | Combine strengths of both | Low |\n",
    "| Quantile regression | Predict delay distributions | Medium |\n",
    "| 2020-2021 data analysis | Model/data drift analysis | High |\n",
    "\n",
    "\n",
    "This project demonstrates that **flight delay prediction is feasible at scale** using publicly available data. The Gradient Boosted Trees model achieves Test RMSE of **48.01 minutes** and MAE of **20.45 minutes**, providing actionable predictions for cargo delivery guarantee pricing.\n",
    "\n",
    "The most important predictive signals come from **airport identity, departure time, and recent carrier reliability**,features that are available before departure and free from leakage. At $100.76 per minute of delay [3], our model enables risk-differentiated pricing that can save millions in better-allocated guarantees across the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cedebcfd-65c0-4090-95dc-50126bb7728a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "## References\n",
    "\n",
    "1. **OAG & Microsoft (2025).** \"AI and Trusted Data: Building Resilient Airline Operations.\" *OAG Aviation Intelligence.* Available at: [https://www.oag.com/ai-aviation-operations](https://www.oag.com/ai-aviation-operations). *Used for: $34 billion total U.S. flight delay costs (2022), citing AirHelp estimates.*\n",
    "\n",
    "2. **U.S. Department of Transportation (2024).** \"Air Travel Consumer Report: December 2024, Full Year 2024 Numbers.\" *Bureau of Transportation Statistics.* Available at: [https://www.transportation.gov/briefing-room/air-travel-consumer-report-december-2024-full-year-2024-numbers](https://www.transportation.gov/briefing-room/air-travel-consumer-report-december-2024-full-year-2024-numbers). *Used for: On-time performance statistics (78.1% on-time arrival rate in 2024 = ~22% delayed).*\n",
    "\n",
    "3. **Airlines for America (2024).** \"U.S. Passenger Carrier Delay Costs.\" Available at: [https://www.airlines.org/dataset/u-s-passenger-carrier-delay-costs/](https://www.airlines.org/dataset/u-s-passenger-carrier-delay-costs/). *Used for: $100.76 per minute block time cost estimate (2024), based on DOT Form 41 data.*\n",
    "\n",
    "4. **FedEx (2024).** \"FedEx Service Guide: Money-Back Guarantee Terms and Conditions.\" *FedEx Corporation.* Available at: [https://www.fedex.com/en-us/service-guide.html](https://www.fedex.com/en-us/service-guide.html). *Used for: 60-second delivery precision threshold for money-back guarantees.*\n",
    "\n",
    "5. **IATA (2024).** \"Strengthened Profitability Expected in 2025.\" *IATA Press Release, December 10, 2024.* Available at: [https://www.iata.org/en/pressroom/2024-releases/2024-12-10-01/](https://www.iata.org/en/pressroom/2024-releases/2024-12-10-01/). *Used for: Cargo revenues as percentage of total airline revenues (~15.6% or $157B of $1.007T in 2025).*\n",
    "\n",
    "6. **U.S. DOT Bureau of Transportation Statistics.** \"TranStats: Air Carrier Statistics.\" Available at: [https://www.transtats.bts.gov/](https://www.transtats.bts.gov/). *Used for: ~6.3 million annual U.S. domestic flights (2019 baseline year); raw OTPW flight delay data for model training.*\n",
    "\n",
    "7. **NOAA National Centers for Environmental Information.** \"Local Climatological Data (LCD) Documentation.\" Available at: [https://www.ncei.noaa.gov/pub/data/cdo/documentation/LCD_documentation.pdf](https://www.ncei.noaa.gov/pub/data/cdo/documentation/LCD_documentation.pdf). *Used for: Weather data methodology and variable definitions.*\n",
    "\n",
    "8. **Apache Spark.** \"MLlib: Machine Learning Library.\" *Apache Software Foundation.* Available at: [https://spark.apache.org/docs/latest/ml-classification-regression.html](https://spark.apache.org/docs/latest/ml-classification-regression.html). *Used for: GBT and Linear Regression implementation reference.*\n",
    "\n",
    "**Note on Cost Estimates:** The $100.76/minute cost is an industry average that includes direct operating costs (fuel, crew, maintenance, ownership) based on DOT Form 41 filings from U.S. scheduled passenger airlines [3]. Individual carrier costs vary significantly by aircraft type and route. All monetary projections in this report use this standardized industry benchmark for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91a1224d-374a-45c7-ae2f-240dc5989ff9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Phase 3 Report",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}